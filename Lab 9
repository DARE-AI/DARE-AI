# -*- coding: utf-8 -*-
"""Capital CatBooster XAI
Dataset: Capital Bikeshare

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BHWfRcJDzYWKQeuN1CLEMAcLP2P6YXje

#Lab 10: Explainable AI
### Using SHAP library to visualize and explain the decision made by the ML model

### Learning Objectives
* Learn to use SHAP(Shapely Additive exPlanations) library and force plot to visualize the features most responsible for the label.
* Learn to use catboost library to convert categorical features into numeric.
* Use the pyplot to select the few vital features responsible for the label from the trivial many.

### Install SHAP and Catboost
Install SHAP(Shapely Additive exPlanations) is a package which helps explain the predictions made by ML models using game theoretic approach. Catbooost is a package which helps utilize the categorical data directly into the model.
"""

!pip install shap

!pip3 install catboost

"""### Imports
Import all the necessary libraries for the lab including Pandas, numpy, matplotlib, CatBoost.
"""

import pandas as pd 
import numpy as np 

import shap
shap.initjs()
from catboost import CatBoostRegressor, Pool
import matplotlib.pyplot as plt

"""### Mount Google Drive
In the code cell below, we mount the google drive to the colab environment so that we have access to the local version of the dataset.
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Read CSV
We read the csv file using pandas in the code below.
"""

mydata = pd.read_csv('/content/drive/My Drive/XAI CSV/day.csv')

mydata

"""### Drop Features
The features like 'Name', 'PassengerId', 'Cabin', 'Ticket' are unique and contribute no value towards the model learning. Hence, these features are dropped from the dataset.
"""

mydata.drop(columns=['instant','registered','casual'],inplace=True)
mydata

"""### Categorize into Numerical and Categorical 
The features in the dataset are categorized into numerical and categorical features.
"""

def categorize(data):
  num_columns = []
  cat_columns = []

  for col in data.columns.values:
      if data[col].dtypes == 'int64' or data[col].dtypes == 'float64':
          num_columns += [col]
      else:
          cat_columns += [col]
  return [cat_columns, num_columns]

cat_columns, num_columns = categorize(mydata)[0], categorize(mydata)[1]
print("Categorical values: ", cat_columns)
print("Numerical values: ", num_columns)

"""### Median value
For each of the numerical feature, find the median value and save it as median value of the feature.
"""

median_val = pd.Series()
for col in num_columns:
  median_val[col] = mydata[col].median()
print("Median values for each Numerical features \n\n", median_val)

"""### Handle missing values
As features have missing data in it, these missing values should be replaced before we can train the model. These missing values are replaced by median value generatead in the previous code for numerical features. Missing values for categorical features should be replaced by "Missing value".
"""

def handle_missing_values(data, median_val):
    df = data.copy()
    for col in df:
        if col in median_val.index.values:
            df[col] = df[col].fillna(median_val[col])
        else:
            df[col] = df[col].fillna("Missing value")
    
    return df

mydata = handle_missing_values(mydata, median_val)

mydata

"""### Label and features
Separate the dataset into label and features to prepare for training.
"""

X = mydata.drop('cnt', axis=1)
y = mydata['cnt']

y

minidx = y.idxmin()
minidx

minvalue = y[minidx]
minvalue

maxidx = y.idxmax()
maxidx

maxvalue = y[maxidx]
maxvalue

"""### CatBoost Regressor
We are using CatBoost classifier to train the model and generate SHAP values for each feature.
"""

#State and Area Code as categorical features
categorical_features = ['dteday']
cat = CatBoostRegressor(cat_features=categorical_features).fit(X,y)

#Use Pool to identify categorical features in X dataframe, and identify the return type of catboost library as ShapValues. 
shap_values = pd.DataFrame(
    cat.get_feature_importance(data = Pool(X, cat_features = categorical_features), type='ShapValues')[:,:-1],
    columns = X.columns,
    index = X.index
)

shap_values

shap.summary_plot(shap_values, X, plot_type="bar")

shap_values

shap_values = shap_values.to_numpy()

shap.summary_plot(shap_values, X)

shap.dependence_plot("weathersit", shap_values, X)

shap_values = pd.DataFrame(shap_values, columns=X.columns, index=X.index)

"""### Assessing the most risked factors for each passenger
The plot below shows for each passenger relatively how many features are affecting the probability of survival. In most of the passengers, it looks like the number of features highly affecting the probability of survival is very close. In nature it is often found that the greatest part of an outcome is due to a tiny number of causes, and is also called pareto principle.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 

#for loop through each of the rows and sort SHAP values for each row
for i in shap_values.index:
  plt.plot(range(shap_values.shape[1]), shap_values.iloc[i, :].sort_values())

plt.title('All risky passengers')
plt.ylabel('SHAP')
plt.xlabel('Features sorted by SHAP (for each passenger)')

#As the SHAP values are sorted, the x-axis label will be different for each passenger.

"""### Individual Instance
This code cell picks the third instance from the dataset to visualize how each feature plays the importance to it's respective label. 
"""

X_obs = X.loc[623,:]
X_obs = X_obs.to_frame().T
X_obs.index = ['Observed']
X_obs

X_obs1 = X.loc[667,:]
X_obs1 = X_obs1.to_frame().T
X_obs1.index = ['Observed']
X_obs1

"""### Visualizing SHAP value for the instance 
The SHAP value for the third instance of the dataset is visualized where positive value has more influence on the label and negative value has less infleunce on the label.
"""

shap_obs = shap_values.loc[623,:]
shap_obs = shap_obs.to_frame().T.round(3).astype(str)
shap_obs.index = ['SHAP']
shap_obs = shap_obs.style.apply(lambda x:["background:pink" if v[0]!='-' else "background:lightblue" for v in x], axis = 1)
shap_obs

shap_obs1 = shap_values.loc[667,:]
shap_obs1 = shap_obs1.to_frame().T.round(3).astype(str)
shap_obs1.index = ['SHAP']
shap_obs1 = shap_obs1.style.apply(lambda x:["background:pink" if v[0]!='-' else "background:lightblue" for v in x], axis = 1)
shap_obs1

"""### Analyzing force plot
The force plot provides the SHAP values which basically tell us which features are most likely to affect the label. Pink colored (positive values) part dictates the features which have more effect on the label. As we go from left to right, the probability of label being true is higher. Blue colored (negative values) part dictates the features which have less effect on label. As we go from right to left, the probability of label being false is higher.
"""

X_obs = X.loc[623,:]
X_obs = X_obs.to_frame().T
X_obs.index = ['Observed']
X_obs

ans = X['hum'].mean()
print(ans)

shap.force_plot(
    base_value = 0, 
    shap_values = np.array(shap_values.loc[623,:]), 
    features = X.loc[623,:],
    show = False,
    matplotlib=True
)
plt.tight_layout()

X_obs = X.loc[667,:]
X_obs = X_obs.to_frame().T
X_obs.index = ['Observed']
X_obs

ans = X['hum'].mean()
print(ans)

shap.force_plot(
    base_value = 0, 
    shap_values = np.array(shap_values.loc[667,:]), 
    features = X.loc[667,:],
    show = False,
    matplotlib=True
)
plt.tight_layout()

"""### Risk factors in single passenger
Here we visualize the features that highly affect the label for a single passenger.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

SHAP_values = shap_values.iloc[623,:].sort_values()
plt.plot(range(shap_values.shape[1]), SHAP_values, '-bo')
plt.hlines(0, -.5, shap_values.shape[1] - .5, color = 'red')
plt.ylabel('SHAP')
plt.xlabel('Features sorted by SHAP')
plt.title('Rider (id: {})'.format(623))
plt.xticks(range(shap_values.shape[1]), SHAP_values.index, rotation=90)

X_obs

y_obs = y.iloc[623]
print("cnt: ", y_obs)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

SHAP_values1 = shap_values.iloc[667,:].sort_values()
plt.plot(range(shap_values.shape[1]), SHAP_values1, '-bo')
plt.hlines(0, -.5, shap_values.shape[1] - .5, color = 'red')
plt.ylabel('SHAP')
plt.xlabel('Features sorted by SHAP')
plt.title('Rider (id: {})'.format(667))
plt.xticks(range(shap_values.shape[1]), SHAP_values1.index, rotation=90)

X_obs1

y_obs1 = y.iloc[667]
print("Cnt: ", y_obs1)

"""### Cumulative sum of the SHAP values
As we see in the plot below, the vertical line separates the negative and positive cumulative SHAP values of the features. Cumulative sum helps us separate vital few causes from the trivial many. As we can see in the plot, four major features seem to be directly affecting the label negatively in this case.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 

cum_SHAP_values = SHAP_values.cumsum()
cum_range = max(cum_SHAP_values) - min(cum_SHAP_values)

plt.plot(range(shap_values.shape[1]), cum_SHAP_values, '-bo')
plt.vlines(shap_values.shape[1] - (cum_SHAP_values > 0).sum() - .5, min(cum_SHAP_values) - .05 * cum_range, max(cum_SHAP_values) + .05 * cum_range, color = 'red')
plt.hlines(0, -.5, shap_values.shape[1] - .5, color = 'red')
plt.ylabel('SHAP cumulative sum')
plt.xlabel('Features sorted by SHAP')
plt.title('Rider (id: {})'.format(623))
plt.xticks(range(shap_values.shape[1]), cum_SHAP_values.index, rotation=90)

X_obs

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 

cum_SHAP_values1 = SHAP_values1.cumsum()
cum_range = max(cum_SHAP_values1) - min(cum_SHAP_values1)

plt.plot(range(shap_values.shape[1]), cum_SHAP_values1, '-bo')
plt.vlines(shap_values.shape[1] - (cum_SHAP_values1 > 0).sum() - .5, min(cum_SHAP_values1) - .05 * cum_range, max(cum_SHAP_values1) + .5 * cum_range, color = 'red')
plt.hlines(0, -.5, shap_values.shape[1] - .5, color = 'red')
plt.ylabel('SHAP cumulative sum')
plt.xlabel('Features sorted by SHAP')
plt.title('Rider (id: {})'.format(667))
plt.xticks(range(shap_values.shape[1]), cum_SHAP_values1.index, rotation=90)

X_obs1

"""**Can you show a comparison of force plot for different instance of Female and Male passenger? Explain what you observation.**"""
